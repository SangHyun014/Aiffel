{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bda7692",
   "metadata": {},
   "source": [
    "# 루브릭\n",
    "1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.\n",
    "    - 구두점, 대소문자, 띄어쓰기 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다.\n",
    "2. seq2seq 기반의 번역기 모델이 정상적으로 구동된다.\n",
    "    - seq2seq 모델 훈련 결과를 그래프로 출력해보고, validation loss 그래프가 우하향하는 경향성을 보인다.\n",
    "3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.\n",
    "    - 테스트용 디코더 모델이 정상적으로 만들어졌으며, input(영어)와 output(프랑스어) 모두 한글로 번역해서 결과를 출력해보았고, 둘의 내용이 유사함을 확인하였다.\n",
    "    \n",
    "## 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728d59d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37264c75",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f215a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 217975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150085</th>\n",
       "      <td>I have never seen anyone like him.</td>\n",
       "      <td>Je n'ai jamais vu quelqu'un comme lui.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208052</th>\n",
       "      <td>She began doing her homework immediately after...</td>\n",
       "      <td>Elle commença à faire ses devoirs immédiatemen...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28252</th>\n",
       "      <td>The crowd clapped.</td>\n",
       "      <td>La foule applaudit.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151922</th>\n",
       "      <td>Put on your pajamas and go to bed.</td>\n",
       "      <td>Mettez-vous en pyjama et allez au lit.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181295</th>\n",
       "      <td>This is the fastest car in our showroom.</td>\n",
       "      <td>C'est la bagnole la plus rapide de notre hall ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "150085                 I have never seen anyone like him.   \n",
       "208052  She began doing her homework immediately after...   \n",
       "28252                                  The crowd clapped.   \n",
       "151922                 Put on your pajamas and go to bed.   \n",
       "181295           This is the fastest car in our showroom.   \n",
       "\n",
       "                                                      fra  \\\n",
       "150085             Je n'ai jamais vu quelqu'un comme lui.   \n",
       "208052  Elle commença à faire ses devoirs immédiatemen...   \n",
       "28252                                 La foule applaudit.   \n",
       "151922             Mettez-vous en pyjama et allez au lit.   \n",
       "181295  C'est la bagnole la plus rapide de notre hall ...   \n",
       "\n",
       "                                                       cc  \n",
       "150085  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "208052  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "28252   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "151922  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "181295  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99ca081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66350</th>\n",
       "      <td>Tom hasn't arrived yet.</td>\n",
       "      <td>Tom n'est pas encore arrivé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69466</th>\n",
       "      <td>He did not speak at all.</td>\n",
       "      <td>Il n'a absolument rien dit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84978</th>\n",
       "      <td>You're a horrible driver.</td>\n",
       "      <td>Tu conduis très mal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87093</th>\n",
       "      <td>I didn't mean to say that.</td>\n",
       "      <td>Je ne voulais pas dire ça.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65088</th>\n",
       "      <td>She's younger than him.</td>\n",
       "      <td>Elle est plus jeune que lui.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              eng                           fra\n",
       "66350     Tom hasn't arrived yet.  Tom n'est pas encore arrivé.\n",
       "69466    He did not speak at all.   Il n'a absolument rien dit.\n",
       "84978   You're a horrible driver.          Tu conduis très mal.\n",
       "87093  I didn't mean to say that.    Je ne voulais pas dire ça.\n",
       "65088     She's younger than him.  Elle est plus jeune que lui."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][60000:93000] # 5만개 샘플 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618a620f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['You were there, right?', 'You will stay at home.',\n",
       "       \"You won't be punished.\", ..., 'What time did you wake up?',\n",
       "       'What time did you wake up?', 'What time did you wake up?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#영어와 프랑스어 분리하기\n",
    "lines_np_eng= lines['eng'].to_numpy()\n",
    "lines_np_fra= lines['fra'].to_numpy()\n",
    "lines_np_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215a693",
   "metadata": {},
   "source": [
    "## 정제, 정규화, 전처리 하기\n",
    "#### 필요한 함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58eaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "\n",
    "def preprocess(line, plus_token = True):\n",
    "    #소문자로 변경하기\n",
    "    line = line.lower().strip()\n",
    "    #구두점 분리하기\n",
    "    line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line)\n",
    "    line = re.sub(r'[\" \"]+', \" \", line)\n",
    "    line = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", line)\n",
    "    \n",
    "    line = line.strip()\n",
    "    \n",
    "    if plus_token == True:\n",
    "        line = sos_token + line + eos_token\n",
    "        \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b0d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화 함수\n",
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(num_words=7000,\n",
    "                         filters=' ',\n",
    "                         oov_token='<unk>')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4af3f0",
   "metadata": {},
   "source": [
    "#### 영어, 프랑스어 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2377b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lines = []\n",
    "fra_lines = []\n",
    "\n",
    "for eng, fra in zip(lines.eng, lines.fra):\n",
    "    if len(eng) == 0: continue\n",
    "    if len(fra) == 0: continue\n",
    "        \n",
    "    eng_lines.append(preprocess(eng, plus_token=False))\n",
    "    fra_lines.append(preprocess(fra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a1be4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eng_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f5c628a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 15, 105, 23, 374, 34, 19, 7, 22, 8, 6, 3],\n",
       " [2, 15, 3036, 151, 78, 4, 3],\n",
       " [2, 15, 13, 1135, 8, 3723, 4, 3],\n",
       " [2, 10, 19, 347, 8, 16, 1519, 4, 3],\n",
       " [2, 15, 13, 389, 8, 16, 1519, 4, 3],\n",
       " [2, 10, 19, 1647, 8, 17, 4, 3],\n",
       " [2, 15, 443, 176, 9, 5098, 4, 3],\n",
       " [2, 15, 443, 176, 9, 35, 20, 128, 278, 4, 3],\n",
       " [2, 15, 443, 176, 9, 26, 841, 72, 4, 3],\n",
       " [2, 10, 1136, 176, 9, 10, 841, 72, 4, 3]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tensor, eng_tokenizer = tokenize(eng_lines)\n",
    "fra_tensor, fra_tokenizer = tokenize(fra_lines)\n",
    "fra_tensor[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fdbb6",
   "metadata": {},
   "source": [
    "#### input, target 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3021f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = eng_tensor\n",
    "#종료 토큰 제거\n",
    "decoder_input = [[char for char in line if char != fra_tokenizer.word_index['<end>']] for line in fra_tensor]\n",
    "decoder_target = [[char for char in line if char != fra_tokenizer.word_index['<start>']] for line in fra_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda4e8b3",
   "metadata": {},
   "source": [
    "#### padding 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be262d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor):\n",
    "    total_data_text = list(tensor)\n",
    "    num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "    max_tokens = max(num_tokens)\n",
    "    maxlen = int(max_tokens)\n",
    "    tensor = pad_sequences(tensor, padding='post', maxlen=maxlen)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbaa852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기 :  (33000, 10)\n",
      "프랑스어 입력데이터의 크기 :  (33000, 17)\n",
      "프랑스어 출력데이터의 크기 :  (33000, 17)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_tensor(encoder_input)\n",
    "decoder_input = pad_tensor(decoder_input)\n",
    "decoder_target = pad_tensor(decoder_target)\n",
    "print('영어 데이터의 크기 : ', encoder_input.shape)\n",
    "print('프랑스어 입력데이터의 크기 : ', decoder_input.shape)\n",
    "print('프랑스어 출력데이터의 크기 : ', decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d7b9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index)+1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index)+1\n",
    "\n",
    "max_eng_seq_len = encoder_input.shape[1]\n",
    "max_fra_seq_len = decoder_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c21cf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 5795\n",
      "프랑스어 단어장의 크기 : 8297\n",
      "영어 시퀀스의 최대 길이 : 10\n",
      "프랑스어 시퀀스의 최대 길이 : 17\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이 :', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이 :', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0430f0",
   "metadata": {},
   "source": [
    "#### train, test dataset 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77082ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "949c82a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (30000, 10)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (30000, 17)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (30000, 17)\n",
      "영어 학습데이터의 크기(shape) : (3000, 10)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (3000, 17)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (3000, 17)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :', encoder_input_train.shape)\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',decoder_input_train.shape)\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',decoder_target_train.shape)\n",
    "print('영어 학습데이터의 크기(shape) :', encoder_input_test.shape)\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',decoder_input_test.shape)\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec71dd3",
   "metadata": {},
   "source": [
    "## Embedding layer 사용하기\n",
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94a54297",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 1024\n",
    "hidden_size = 1024\n",
    "\n",
    "encoder_inputs = Input(shape=(None, ), name='encoder_input')\n",
    "enc_emb = Embedding(eng_vocab_size, embedding_size, input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, dropout=0.6, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee06bdc",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "084dd269",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='decoder_input')\n",
    "dec_emb = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, dropout=0.6, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf7d574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db26196",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "332f4da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 1024)   5934080     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 1024)   8496128     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 1024)   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 1024)   0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 1024), (None 8392704     masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 1024), 8392704     masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8297)   8504425     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 39,720,041\n",
      "Trainable params: 39,720,041\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79283647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 71s 41ms/step - loss: 1.8040 - val_loss: 1.4635\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 37s 40ms/step - loss: 1.3175 - val_loss: 1.2313\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 38s 41ms/step - loss: 1.1031 - val_loss: 1.1033\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 39s 42ms/step - loss: 0.9498 - val_loss: 1.0316\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.8335 - val_loss: 0.9830\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.7461 - val_loss: 0.9571\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.6810 - val_loss: 0.9392\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.6319 - val_loss: 0.9390\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.6009 - val_loss: 0.9454\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.5743 - val_loss: 0.9516\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.5615 - val_loss: 0.9533\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.5508 - val_loss: 0.9566\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.5362 - val_loss: 0.9560\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 38s 41ms/step - loss: 0.5216 - val_loss: 0.9604\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.5055 - val_loss: 0.9520\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4830 - val_loss: 0.9468\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4744 - val_loss: 0.9487\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4669 - val_loss: 0.9504\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4599 - val_loss: 0.9507\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4497 - val_loss: 0.9470\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4399 - val_loss: 0.9416\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4299 - val_loss: 0.9355\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4218 - val_loss: 0.9356\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4153 - val_loss: 0.9373\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4108 - val_loss: 0.9328\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.4034 - val_loss: 0.9346\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3947 - val_loss: 0.9358\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3935 - val_loss: 0.9393\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3932 - val_loss: 0.9392\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3910 - val_loss: 0.9410\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3884 - val_loss: 0.9401\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3851 - val_loss: 0.9407\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3821 - val_loss: 0.9407\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3776 - val_loss: 0.9441\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3746 - val_loss: 0.9407\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3712 - val_loss: 0.9381\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3672 - val_loss: 0.9453\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3657 - val_loss: 0.9404\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3642 - val_loss: 0.9439\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3615 - val_loss: 0.9435\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3595 - val_loss: 0.9459\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3575 - val_loss: 0.9404\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3553 - val_loss: 0.9506\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3535 - val_loss: 0.9464\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3537 - val_loss: 0.9520\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3506 - val_loss: 0.9524\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3490 - val_loss: 0.9509\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3487 - val_loss: 0.9515\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3476 - val_loss: 0.9531\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 39s 41ms/step - loss: 0.3470 - val_loss: 0.9586\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train],\n",
    "                    y=decoder_target_train,\n",
    "                    validation_data = ([encoder_input_test, decoder_input_test],decoder_target_test),\n",
    "                    batch_size=32,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3bc9f",
   "metadata": {},
   "source": [
    "validation loss graph로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "709a06d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12025c5c",
   "metadata": {},
   "source": [
    "## 모델 구현하기\n",
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19efaf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 1024)        5934080   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 1024)        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 1024), (None, 102 8392704   \n",
      "=================================================================\n",
      "Total params: 14,326,784\n",
      "Trainable params: 14,326,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8188e",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54dc0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(embedding_size,))\n",
    "decoder_state_input_c = Input(shape=(embedding_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6adc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "160fefd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 1024)   8496128     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 1024), 8392704     embedding_2[0][0]                \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8297)   8504425     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 25,393,257\n",
      "Trainable params: 25,393,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2]+decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f0f06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <start>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16e6bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b334829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f8d90",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45f35ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: i remember your father . \n",
      "정답 문장: je me rappelle de votre p re . \n",
      "번역기가 번역한 문장:  je me me ton ton to\n",
      "-----------------------------------\n",
      "입력 문장: i always eat breakfast . \n",
      "정답 문장: je prends toujours un petit d jeuner . \n",
      "번역기가 번역한 문장:  je tudie encore qu\n",
      "-----------------------------------\n",
      "입력 문장: she was very rude to him . \n",
      "정답 문장: elle a t tr s grossi re son gard . \n",
      "번역기가 번역한 문장:  elle fut l de so\n",
      "-----------------------------------\n",
      "입력 문장: we d make a perfect team . \n",
      "정답 문장: nous <unk> une parfaite quipe . \n",
      "번역기가 번역한 문장:  nous nous un un u\n",
      "-----------------------------------\n",
      "입력 문장: do you have a solution ? \n",
      "정답 문장: as tu une solution ? \n",
      "번역기가 번역한 문장:  avez tu une la ? \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [4,153,576,1358,2883]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654bd67",
   "metadata": {},
   "source": [
    "모델이 생성한 문장을 하나씩 비교하면서 보겠습니다.\n",
    "1.\n",
    "I remember your father -> 나는 너의 아빠를 믿는다\n",
    "je me me ton ton to ->나는 머리를 숙이고 있다\n",
    "2.\n",
    "I always eat breakfast -> 나는 항상 아침을 먹는다\n",
    "je tudie encore qu ->(번역이 올바르게 되지 않음)\n",
    "3.\n",
    "she was very rude to him ->그녀는 그에게 매우 무례했습니다\n",
    "elle fut I de so -> 그 여자는 소원이었다\n",
    "4.\n",
    "we d make a perfect team. ->우리는 완벽한 팀을 만들었습니다\n",
    "nous nous un un u -> 단결하다\n",
    "5.\n",
    "do you have a solution? ->해결책이 있습니까?\n",
    "avez tu une la? ->avez tu une la\n",
    "\n",
    "다음과 같이 볼 수 있고 변역한 결과를 본다면 학습이 잘 이루어 지지 않았음을 알 수 있습니다.\n",
    "학습의 하이퍼파라미터라 볼 수 있는 embedding size와 hidden_size의 값을 변경해주면서 실험을 했지만 유의미한 결과를 볼 수 없었습니다.\n",
    "Exploration에서 자연어 부분을 할땐 추가적인 공부가 필요하다고 생각합니다.\n",
    "다음과 같은 학습을 더 잘 하기 위해 어떤 것이 필요한지 조금 더 생각해 볼 필요가 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
