{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 루브릭\n",
    "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\n",
    "    - 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
    "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\n",
    "    - 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
    "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.\n",
    "    - 한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T05:47:35.476825Z",
     "start_time": "2020-10-22T05:47:35.474309Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:05:13.588841Z",
     "start_time": "2020-10-22T06:05:13.585344Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    questions=[]\n",
    "    answers=[]\n",
    "    with open('data/ChatbotData .csv','r',encoding=\"utf-8\") as f:\n",
    "        for line in f.read().splitlines():\n",
    "            questions.append(line.split(',')[0:1][0])\n",
    "            answers.append(line.split(',')[1:2][0])\n",
    "        questions, answers, test_Q, test_A = train_test_split(questions, answers, test_size=0.05, random_state=42)\n",
    "    return questions, answers, test_Q, test_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:05:14.227786Z",
     "start_time": "2020-10-22T06:05:14.214555Z"
    }
   },
   "outputs": [],
   "source": [
    "questions, test_Q, answers, test_A = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:05:28.374743Z",
     "start_time": "2020-10-22T06:05:28.371984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11232\n",
      "전체 샘플 수 : 11232\n",
      "테스트 샘플 수 : 592\n",
      "테스트 샘플 수 : 592\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))\n",
    "print('테스트 샘플 수 :', len(test_Q))\n",
    "print('테스트 샘플 수 :', len(test_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:05:39.989840Z",
     "start_time": "2020-10-22T06:05:39.986818Z"
    }
   },
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:05:44.883308Z",
     "start_time": "2020-10-22T06:05:44.880322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 어이 없는 헤어짐\n",
      "전처리 후의 22번째 답변 샘플: 예상하지 못한 이별이었네요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(preprocess_sentence(questions[23])))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(preprocess_sentence(answers[23])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:05:58.272916Z",
     "start_time": "2020-10-22T06:05:48.930467Z"
    }
   },
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성.\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:05:58.307545Z",
     "start_time": "2020-10-22T06:05:58.305572Z"
    }
   },
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:07:48.624592Z",
     "start_time": "2020-10-22T06:07:48.621604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [7841]\n",
      "END_TOKEN의 번호 : [7842]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:07:49.679553Z",
     "start_time": "2020-10-22T06:07:49.677232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7843\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:08:20.813625Z",
     "start_time": "2020-10-22T06:08:20.810945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 23번째 질문 샘플: [3268, 7617, 121, 749]\n",
      "정수 인코딩 후의 23번째 답변 샘플: [6324, 122, 1128, 1178, 6373, 7631]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 23번째 질문 샘플: {}'.format(tokenizer.encode(questions[23])))\n",
    "print('정수 인코딩 후의 23번째 답변 샘플: {}'.format(tokenizer.encode(answers[23])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:13:13.563723Z",
     "start_time": "2020-10-22T06:13:13.557325Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9926994301994302\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for q in answers: \n",
    "    if len(q) < 40:\n",
    "        temp.append(q)\n",
    "print(len(temp)/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:13:33.953921Z",
     "start_time": "2020-10-22T06:13:33.951559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이.\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:13:34.221545Z",
     "start_time": "2020-10-22T06:13:34.217932Z"
    }
   },
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "        tokenized_inputs.append(sentence1)\n",
    "        tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:13:35.975825Z",
     "start_time": "2020-10-22T06:13:35.538799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 7843\n",
      "필터링 후의 샘플 개수: 11232\n",
      "필터링 후의 샘플 개수: 11232\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:14.853134Z",
     "start_time": "2020-10-22T06:14:14.847370Z"
    }
   },
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:15.319641Z",
     "start_time": "2020-10-22T06:14:15.316502Z"
    }
   },
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:15.924383Z",
     "start_time": "2020-10-22T06:14:15.918860Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "      def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷-프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:17.536566Z",
     "start_time": "2020-10-22T06:14:17.534081Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:17.944493Z",
     "start_time": "2020-10-22T06:14:17.942312Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:18.462290Z",
     "start_time": "2020-10-22T06:14:18.458314Z"
    }
   },
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "          d_model, num_heads, name=\"attention\")({\n",
    "              'query': inputs,\n",
    "              'key': inputs,\n",
    "              'value': inputs,\n",
    "              'mask': padding_mask\n",
    "          })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "          inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:19.444925Z",
     "start_time": "2020-10-22T06:14:19.440906Z"
    }
   },
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "\t# 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:19.962313Z",
     "start_time": "2020-10-22T06:14:19.956883Z"
    }
   },
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "          shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "          d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "              'query': inputs,\n",
    "              'key': inputs,\n",
    "              'value': inputs,\n",
    "              'mask': look_ahead_mask\n",
    "          })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "          d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "              'query': attention1,\n",
    "              'key': enc_outputs,\n",
    "              'value': enc_outputs,\n",
    "              'mask': padding_mask\n",
    "          })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "          epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "          inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "          outputs=outputs,\n",
    "          name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:34.807380Z",
     "start_time": "2020-10-22T06:14:34.802284Z"
    }
   },
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:36.337818Z",
     "start_time": "2020-10-22T06:14:35.924167Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:36.385109Z",
     "start_time": "2020-10-22T06:14:36.380617Z"
    }
   },
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "\t# 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크하기위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout)(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout)(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:38.906481Z",
     "start_time": "2020-10-22T06:14:37.144574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3062016     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3589376     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 7843)   2015651     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,667,043\n",
      "Trainable params: 8,667,043\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.3 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:40.574311Z",
     "start_time": "2020-10-22T06:14:40.571899Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:41.295992Z",
     "start_time": "2020-10-22T06:14:41.293050Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:14:44.482689Z",
     "start_time": "2020-10-22T06:14:44.351462Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:18:49.325631Z",
     "start_time": "2020-10-22T06:14:45.733008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "176/176 [==============================] - 30s 52ms/step - loss: 1.4690 - accuracy: 0.0211\n",
      "Epoch 2/50\n",
      "176/176 [==============================] - 9s 51ms/step - loss: 1.2183 - accuracy: 0.0434\n",
      "Epoch 3/50\n",
      "176/176 [==============================] - 9s 52ms/step - loss: 1.0481 - accuracy: 0.0496\n",
      "Epoch 4/50\n",
      "176/176 [==============================] - 9s 52ms/step - loss: 0.9796 - accuracy: 0.0510\n",
      "Epoch 5/50\n",
      "176/176 [==============================] - 9s 52ms/step - loss: 0.9320 - accuracy: 0.0538\n",
      "Epoch 6/50\n",
      "176/176 [==============================] - 9s 52ms/step - loss: 0.8914 - accuracy: 0.0561\n",
      "Epoch 7/50\n",
      "176/176 [==============================] - 9s 52ms/step - loss: 0.8509 - accuracy: 0.0585\n",
      "Epoch 8/50\n",
      "176/176 [==============================] - 9s 52ms/step - loss: 0.8046 - accuracy: 0.0617\n",
      "Epoch 9/50\n",
      "176/176 [==============================] - 9s 52ms/step - loss: 0.7552 - accuracy: 0.0656\n",
      "Epoch 10/50\n",
      "176/176 [==============================] - 9s 52ms/step - loss: 0.7012 - accuracy: 0.0704\n",
      "Epoch 11/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.6437 - accuracy: 0.0762\n",
      "Epoch 12/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.5859 - accuracy: 0.0825\n",
      "Epoch 13/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.5283 - accuracy: 0.0883\n",
      "Epoch 14/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.4719 - accuracy: 0.0948\n",
      "Epoch 15/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.4184 - accuracy: 0.1010\n",
      "Epoch 16/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.3698 - accuracy: 0.1073\n",
      "Epoch 17/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.3252 - accuracy: 0.1126\n",
      "Epoch 18/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.2856 - accuracy: 0.1183\n",
      "Epoch 19/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.2506 - accuracy: 0.1239\n",
      "Epoch 20/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.2204 - accuracy: 0.1285\n",
      "Epoch 21/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.1961 - accuracy: 0.1327\n",
      "Epoch 22/50\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.1744 - accuracy: 0.1361\n",
      "Epoch 23/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.1581 - accuracy: 0.1389\n",
      "Epoch 24/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.1386 - accuracy: 0.1429\n",
      "Epoch 25/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.1218 - accuracy: 0.1460\n",
      "Epoch 26/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.1083 - accuracy: 0.1486\n",
      "Epoch 27/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.0951 - accuracy: 0.1518\n",
      "Epoch 28/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.0854 - accuracy: 0.1539\n",
      "Epoch 29/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.0753 - accuracy: 0.1561\n",
      "Epoch 30/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0690 - accuracy: 0.1577\n",
      "Epoch 31/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.0625 - accuracy: 0.1594\n",
      "Epoch 32/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0582 - accuracy: 0.1603\n",
      "Epoch 33/50\n",
      "176/176 [==============================] - 9s 54ms/step - loss: 0.0539 - accuracy: 0.1613\n",
      "Epoch 34/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0512 - accuracy: 0.1620\n",
      "Epoch 35/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0470 - accuracy: 0.1631\n",
      "Epoch 36/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0437 - accuracy: 0.1639\n",
      "Epoch 37/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0411 - accuracy: 0.1648\n",
      "Epoch 38/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0399 - accuracy: 0.1650\n",
      "Epoch 39/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0362 - accuracy: 0.1660\n",
      "Epoch 40/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0353 - accuracy: 0.1663\n",
      "Epoch 41/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0333 - accuracy: 0.1668\n",
      "Epoch 42/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0318 - accuracy: 0.1673\n",
      "Epoch 43/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0306 - accuracy: 0.1675\n",
      "Epoch 44/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0289 - accuracy: 0.1680\n",
      "Epoch 45/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0272 - accuracy: 0.1685\n",
      "Epoch 46/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0266 - accuracy: 0.1685\n",
      "Epoch 47/50\n",
      "176/176 [==============================] - 10s 55ms/step - loss: 0.0257 - accuracy: 0.1687\n",
      "Epoch 48/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0242 - accuracy: 0.1693\n",
      "Epoch 49/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0240 - accuracy: 0.1692\n",
      "Epoch 50/50\n",
      "176/176 [==============================] - 10s 54ms/step - loss: 0.0227 - accuracy: 0.1695\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd27d7b3490>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], 'r')\n",
    "plt.title('Model validation accuracy (resnet_50 vs plain_50)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "안정적으로 loss가 수렴하는 모습을 볼 수 잇다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:18:52.034973Z",
     "start_time": "2020-10-22T06:18:52.022859Z"
    }
   },
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없으므로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "      # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "        break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:18:53.910945Z",
     "start_time": "2020-10-22T06:18:53.901300Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:20:09.113437Z",
     "start_time": "2020-10-22T06:20:08.790002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 입력 : 죽을 것 같아\n",
      "예측 출력 : 돈 없어도 할 수 있는게 많아요\n",
      "-------------------------\n",
      "질문 입력 : 내일 수학여행가!\n",
      "예측 출력 : 뭘 입어도 멋져요.\n",
      "-------------------------\n",
      "질문 입력 : 정말. 정말 쉽지가 않네. 이럴 땐 어떡해야 할까\n",
      "예측 출력 : 헤어짐에는 추억이 남는건 천천히 잊는 건 정리하는게 건 없어요.\n",
      "-------------------------\n",
      "질문 입력 : 이별후 너무 외로워ㅠ\n",
      "예측 출력 : 많은 시간이 흘렀네요.\n",
      "-------------------------\n",
      "질문 입력 : 싸웠을 때 어떻게 해?\n",
      "예측 출력 : 기대를 마음이 버려야 덜 다칠 거예요.\n",
      "-------------------------\n",
      "질문 입력 : 내 사랑의 끝은 이별이지만\n",
      "예측 출력 : 한켠에 상처가 있을테니까요.\n",
      "-------------------------\n",
      "질문 입력 : 어떻게 벌주어야 할까.\n",
      "예측 출력 : 좋은 놀아요.\n",
      "-------------------------\n",
      "질문 입력 : 발 부었어\n",
      "예측 출력 : 맥주병 같은 걸로 살살 문질러 주세요\n",
      "-------------------------\n",
      "질문 입력 : 썸 타는 것도 귀찮아.\n",
      "예측 출력 : 다양하게 배우면 좋죠.\n",
      "-------------------------\n",
      "질문 입력 : 좋아하는 애랑 전화하면\n",
      "예측 출력 : 후회하지 않을 자신이 있다면 연락하세요.\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('질문 입력 : {}'.format(test_Q[i]))\n",
    "    print('예측 출력 : {}'.format(sentence_generation(test_Q[i])))\n",
    "    print('-'*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 대답이 적절한 대답을 하고 있는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T06:20:17.669217Z",
     "start_time": "2020-10-22T06:20:17.421605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 입력 : 발 부었어\n",
      "정답 출력 : 맥주병 같은 걸로 살살 문질러 주세요\n"
     ]
    }
   ],
   "source": [
    "print('질문 입력 : {}'.format(test_Q[7]))\n",
    "print('정답 출력 : {}'.format(test_A[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 모델은 중요한 모델로 한 번쯤은 다루어 보고 싶었는데 좋은 기회가 된 것 같습니다.\n",
    "학습도 적절히 하여 결과도 만족스러웠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
